{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a logistic regression based on the bank data provided. \n",
    "\n",
    "The data is based on the marketing campaign efforts of a Portuguese banking institution. The classification goal is to predict if the client will subscribe a term deposit (variable y).\n",
    "\n",
    "Note that the first column of the dataset is the index.\n",
    "\n",
    "Source: [Moro et al., 2014] S. Moro, P. Cortez and P. Rita. A Data-Driven Approach to Predict the Success of Bank Telemarketing. Decision Support Systems, Elsevier, 62:22-31, June 2014"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding Logistic Regression Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Using the same code as in the previous exercise, try to interpret the summary table.\n",
    "\n",
    "### More information about the dataset: \n",
    "Note that <i> interest rate</i> indicates the 3-month interest rate between banks and <i> duration </i> indicates the time since the last contact was made with a given consumer. The <i> previous </i> variable shows whether the last marketing campaign was successful with this customer. The <i>March</i> and <i> May </i> are Boolean variables that account for when the call was made to the specific customer and <i> credit </i> shows if the customer has enough credit to avoid defaulting.\n",
    "\n",
    "<i> Notes: \n",
    "    <li> the first column of the dataset is an index one; </li>\n",
    "    <li> you don't need the graph for this exercise; </li>\n",
    "    <li> the dataset used is much bigger </li>\n",
    "</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the ‘Bank_data.csv’ dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Bank-data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interest_rate    0\n",
      "credit           0\n",
      "march            0\n",
      "may              0\n",
      "previous         0\n",
      "duration         0\n",
      "y                0\n",
      "dtype: int64\n",
      "[0. 1.]\n",
      "[1. 0.]\n",
      "[0. 1.]\n",
      "[0. 1.]\n",
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "# copy the dataset into a new dataframe\n",
    "\n",
    "new_df = data.copy()\n",
    "\n",
    "# remove the index column that comes with the data\n",
    "\n",
    "new_df = new_df.drop(['Unnamed: 0'], axis = 1)\n",
    "\n",
    "# seeing that the column y is to classify whether the client will subscribe into term deposit with the bank\n",
    "# as such, we want to know if the campaign was successful, so we need to assign 1 and 0 to the label 'yes' and 'no'\n",
    "\n",
    "new_df['y'] = new_df['y'].map({'yes': 1, 'no': 0})\n",
    "\n",
    "# assessing values in the column May suggest that is not boolean in nature\n",
    "# therefore, we need to correct this and assign values to 1 when it is more than 1\n",
    "\n",
    "new_df.loc[new_df['may'] > 1, ['may']] = 1\n",
    "\n",
    "# check for any missing/ null values\n",
    "\n",
    "print(new_df.isnull().sum())\n",
    "\n",
    "# ensure the boolean values have been assigned accordingly for each columns (credit, march, may, previous, y)\n",
    "\n",
    "bol = ['credit','march','may','previous','y']\n",
    "\n",
    "for i in bol:\n",
    "    print(new_df[i].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>interest_rate</th>\n",
       "      <th>credit</th>\n",
       "      <th>march</th>\n",
       "      <th>may</th>\n",
       "      <th>previous</th>\n",
       "      <th>duration</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.334</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.767</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>274.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.858</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.120</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>686.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.856</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>1.334</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>0.861</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>806.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>0.879</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>290.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>0.877</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>473.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>4.965</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>518 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     interest_rate  credit  march  may  previous  duration  y\n",
       "0            1.334     0.0    1.0  0.0       0.0     117.0  0\n",
       "1            0.767     0.0    0.0  1.0       1.0     274.0  1\n",
       "2            4.858     0.0    1.0  0.0       0.0     167.0  0\n",
       "3            4.120     0.0    0.0  0.0       0.0     686.0  1\n",
       "4            4.856     0.0    1.0  0.0       0.0     157.0  0\n",
       "..             ...     ...    ...  ...       ...       ... ..\n",
       "513          1.334     0.0    1.0  0.0       0.0     204.0  0\n",
       "514          0.861     0.0    0.0  1.0       1.0     806.0  1\n",
       "515          0.879     0.0    0.0  0.0       0.0     290.0  0\n",
       "516          0.877     0.0    0.0  1.0       1.0     473.0  1\n",
       "517          4.965     0.0    0.0  0.0       0.0     142.0  0\n",
       "\n",
       "[518 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Declare the dependent and independent variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use 'duration' as the independent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = new_df['duration']\n",
    "y = new_df['y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.546118\n",
      "         Iterations 7\n"
     ]
    }
   ],
   "source": [
    "x = sm.add_constant(x1)\n",
    "log_reg = sm.Logit(y,x)\n",
    "log_reg_result = log_reg.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>y</td>        <th>  No. Observations:  </th>  <td>   518</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   516</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>     1</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Mon, 15 May 2023</td> <th>  Pseudo R-squ.:     </th>  <td>0.2121</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>06:38:27</td>     <th>  Log-Likelihood:    </th> <td> -282.89</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -359.05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>5.387e-35</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>        <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>    <td>   -1.7001</td> <td>    0.192</td> <td>   -8.863</td> <td> 0.000</td> <td>   -2.076</td> <td>   -1.324</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>duration</th> <td>    0.0051</td> <td>    0.001</td> <td>    9.159</td> <td> 0.000</td> <td>    0.004</td> <td>    0.006</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:                  518\n",
       "Model:                          Logit   Df Residuals:                      516\n",
       "Method:                           MLE   Df Model:                            1\n",
       "Date:                Mon, 15 May 2023   Pseudo R-squ.:                  0.2121\n",
       "Time:                        06:38:27   Log-Likelihood:                -282.89\n",
       "converged:                       True   LL-Null:                       -359.05\n",
       "Covariance Type:            nonrobust   LLR p-value:                 5.387e-35\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         -1.7001      0.192     -8.863      0.000      -2.076      -1.324\n",
       "duration       0.0051      0.001      9.159      0.000       0.004       0.006\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg_result.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Fitting the model results in 7 iterations\n",
    "\n",
    "With 518 observations, only 516 variables are estimated\n",
    "\n",
    "Pseudo R-squared: 0.21, which is between the range of 0.2 - 0.4. Therefore, it is in 'acceptable region'\n",
    "\n",
    "Log-Likelihood is -282.89, which is lower than LL-Null (-359.05) in the absolute terms. Since it does not converge, this means that the likelihood of the \n",
    "regression model to not have independent variable(s) is unlikely\n",
    "\n",
    "This further supported by LLR p-value, which lesser than 0.05\n",
    "\n",
    "On the coefficient side, the weight of the constant (-1.7) is bigger than duration(0.0051)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretting single predictor and binary predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pred = pd.read_csv('Binary+predictors.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigining appropriate lables\n",
    "# Admission (yes: 1, no: 0)\n",
    "# Gender (male: 1, female: 0)\n",
    "\n",
    "data_pred['Admitted'] = data_pred['Admitted'].map({'Yes': 1, 'No': 0})\n",
    "data_pred['Gender'] = data_pred['Gender'].map({'Male': 1, 'Female': 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's do only Gender as single independent variables\n",
    "\n",
    "x1 = data_pred['Gender']\n",
    "y = data_pred['Admitted']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.572260\n",
      "         Iterations 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>Admitted</td>     <th>  No. Observations:  </th>  <td>   168</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   166</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>     1</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Mon, 15 May 2023</td> <th>  Pseudo R-squ.:     </th>  <td>0.1659</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>06:38:27</td>     <th>  Log-Likelihood:    </th> <td> -96.140</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -115.26</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>6.283e-10</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "     <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>  <td>    1.4351</td> <td>    0.287</td> <td>    4.995</td> <td> 0.000</td> <td>    0.872</td> <td>    1.998</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Gender</th> <td>   -2.0786</td> <td>    0.363</td> <td>   -5.727</td> <td> 0.000</td> <td>   -2.790</td> <td>   -1.367</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:               Admitted   No. Observations:                  168\n",
       "Model:                          Logit   Df Residuals:                      166\n",
       "Method:                           MLE   Df Model:                            1\n",
       "Date:                Mon, 15 May 2023   Pseudo R-squ.:                  0.1659\n",
       "Time:                        06:38:27   Log-Likelihood:                -96.140\n",
       "converged:                       True   LL-Null:                       -115.26\n",
       "Covariance Type:            nonrobust   LLR p-value:                 6.283e-10\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          1.4351      0.287      4.995      0.000       0.872       1.998\n",
       "Gender        -2.0786      0.363     -5.727      0.000      -2.790      -1.367\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# logistic summary\n",
    "\n",
    "x = sm.add_constant(x1)\n",
    "log_reg = sm.Logit(y,x)\n",
    "log_reg_result = log_reg.fit()\n",
    "log_reg_result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Fitting the model results in 5 iterations\n",
    "\n",
    "With 168 observations, only 166 variables are estimated\n",
    "\n",
    "Pseudo R-squared: 0.16, which explains that the log model is weak\n",
    "\n",
    "The Log-Likelihood and LL-Null are both not converging, which lead to the Gender variable is significant enough (remember this as we will revisit later)\n",
    "\n",
    "On the coefficient side, the weight of the constant is -1.4351 and Gender -2.075 (remember this as we will revisit later)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "What about if we analyse the logit function\n",
    "\n",
    "Take 2 Gender...\n",
    "\n",
    "log(Gender1) = 1.4351 - 2.0786 * Gender1 # Gender 1 = Male\n",
    "log(Gender2) = 1.4351 - 2.0786 * Gender2 # Gender 2 = Female\n",
    "\n",
    "What will we see if we shift the equation\n",
    "\n",
    "Gender1 / Gender 2 = exp(-2.0786)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12510523698442316"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If we intepret the log ratio such as above (Male-to-female)\n",
    "\n",
    "np.exp(-2.0786)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "This means that...\n",
    "\n",
    "A male is 0.000125 times more likely to be accepted\n",
    "\n",
    "The odds decreased by 87.5% (100% - 12.5%) compared to female\n",
    "\n",
    "In the probability terms (12.5%/(100% + 12.5%)), the probability of the male to get accepted is 11.1%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.993270498536442"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If we intepret the log ratio such when we switched the denominator and the numerator (Female-to-male)\n",
    "\n",
    "np.exp(2.0786)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The interpretion has also changed...\n",
    "\n",
    "A female is 7.99 times more likely to be accepted\n",
    "\n",
    "The odds increased by 6.99% (100% - 799%) compared to male\n",
    "\n",
    "In the probability terms (799%/(100% + 799%)), the probability of the female to get accepted is 88.8%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redo again but this time, let's include both SAT and Gender as our predictors\n",
    "\n",
    "x1 = data_pred[['Gender','SAT']]\n",
    "y = data_pred['Admitted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.120117\n",
      "         Iterations 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>Admitted</td>     <th>  No. Observations:  </th>  <td>   168</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   165</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>     2</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Mon, 15 May 2023</td> <th>  Pseudo R-squ.:     </th>  <td>0.8249</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>06:38:27</td>     <th>  Log-Likelihood:    </th> <td> -20.180</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -115.26</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>5.118e-42</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "     <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>  <td>  -66.4040</td> <td>   16.321</td> <td>   -4.068</td> <td> 0.000</td> <td>  -98.394</td> <td>  -34.414</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Gender</th> <td>   -1.9449</td> <td>    0.846</td> <td>   -2.299</td> <td> 0.022</td> <td>   -3.603</td> <td>   -0.287</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SAT</th>    <td>    0.0406</td> <td>    0.010</td> <td>    4.129</td> <td> 0.000</td> <td>    0.021</td> <td>    0.060</td>\n",
       "</tr>\n",
       "</table><br/><br/>Possibly complete quasi-separation: A fraction 0.27 of observations can be<br/>perfectly predicted. This might indicate that there is complete<br/>quasi-separation. In this case some parameters will not be identified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:               Admitted   No. Observations:                  168\n",
       "Model:                          Logit   Df Residuals:                      165\n",
       "Method:                           MLE   Df Model:                            2\n",
       "Date:                Mon, 15 May 2023   Pseudo R-squ.:                  0.8249\n",
       "Time:                        06:38:27   Log-Likelihood:                -20.180\n",
       "converged:                       True   LL-Null:                       -115.26\n",
       "Covariance Type:            nonrobust   LLR p-value:                 5.118e-42\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const        -66.4040     16.321     -4.068      0.000     -98.394     -34.414\n",
       "Gender        -1.9449      0.846     -2.299      0.022      -3.603      -0.287\n",
       "SAT            0.0406      0.010      4.129      0.000       0.021       0.060\n",
       "==============================================================================\n",
       "\n",
       "Possibly complete quasi-separation: A fraction 0.27 of observations can be\n",
       "perfectly predicted. This might indicate that there is complete\n",
       "quasi-separation. In this case some parameters will not be identified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# logistic summary\n",
    "\n",
    "x = sm.add_constant(x1)\n",
    "log_reg = sm.Logit(y,x)\n",
    "log_reg_result = log_reg.fit()\n",
    "log_reg_result.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Fitting the model results in 10 iterations\n",
    "\n",
    "With 168 observations, only 165 variables are estimated\n",
    "\n",
    "Pseudo R-squared: 0.8249, which is better than the previous model. This means that introducing new variables into the model (SAT) significantly improves the model\n",
    "\n",
    "The Log-Likelihood and LL-Null are stil  not converging. The only difference when compared to the previous example is that th example is the 2nd model has a higher log-likelihood (in its relative magnitude). Relative magnitude means that the distance between -29.180 to -115.26 is relatively longer than -96.140 to -115.26.\n",
    "\n",
    "This is also because introduction of new predictor such as SAT is an outstanding predictor (more on that later).\n",
    "\n",
    "On the coefficient side, the weight of the constant is -1.4351 and Gender -2.075 (remember this as we will revisit later)\n",
    "\n",
    "On the coefficient side, the weight of the Gender actually decreases to -1.9449 and SAT, on the other hand, is 0.0406. Looking at the p values, SAT has much lower p values (0.000) & Gender has also a much lower p values (0.022). This means that Gender's p values are getting smaller and may approaching zero, hence the evidence against the null hypothesis there is enough reason to conclude that the observed effect is not due to chance."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "What about if we analyse the logit function\n",
    "\n",
    "Yet again, we will do the same as before with coefficients different\n",
    "\n",
    "Take 2 Gender...\n",
    "\n",
    "log(Gender1) = -66.4040 - 1.9449 * Gender1 # Gender 1 = Male\n",
    "log(Gender2) = -66.4040 - 1.9449 * Gender2 # Gender 2 = Male\n",
    "\n",
    "What will we see if we shift the equation\n",
    "\n",
    "Gender1 / Gender 2 = exp(-1.9449)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14300152277538664"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If we intepret the log ratio such as above (Male-to-female)\n",
    "\n",
    "np.exp(-1.9449)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "This means that...\n",
    "\n",
    "A male is 0.000143 times more likely to be accepted\n",
    "\n",
    "The odds decreased by 85.7% (100% - 14.3%) compared to female.\n",
    "\n",
    "In the probability terms (14.3%/(100% + 14.3%)), the probability of the male to get accepted is 12.5%\n",
    "\n",
    "If we notice these values and compare to the previous example, both the odds and the probability are marginally better now that SAT becomes part of the predictors!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.992932526814459"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If we intepret the log ratio such when we switched the denominator and the numerator (Female-to-male)\n",
    "\n",
    "np.exp(1.9449)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The interpretion has also changed...\n",
    "\n",
    "A female is 6.99 times more likely to be accepted\n",
    "\n",
    "The odds increased by 599% (100% - 699%) compared to male\n",
    "\n",
    "In the probability terms (699%/(100% + 699%)), the probability of the female to get accepted is 87.5%\n",
    "\n",
    "If we notice these values and compare to the previous example, both the odds and the probability are marginally worse now that SAT becomes part of the predictors!\n",
    "\n",
    "Still, even with the SAT scores, the females are 6.99 times more likely to be accepted and the probabolity to enter is still on the good range of above 85%!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting and calculating the accuracy of the model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Instead of creating new data, we can compare the same predictors and compare to the actual data\n",
    "\n",
    "Therefore, we may not need to pass any arguments into the predict() as the default will pass the same data that we load as our predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted values\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.00, 1.00, 1.00, 0.23, 0.02, 0.99, 1.00, 1.00, 1.00, 0.01, 1.00,\n",
       "       1.00, 0.76, 0.00, 0.60, 1.00, 0.11, 0.12, 0.51, 1.00, 1.00, 1.00,\n",
       "       0.00, 0.01, 0.97, 1.00, 0.48, 0.99, 1.00, 0.99, 0.00, 0.83, 0.25,\n",
       "       1.00, 1.00, 1.00, 0.31, 1.00, 0.23, 0.00, 0.02, 0.45, 1.00, 0.00,\n",
       "       0.99, 0.00, 0.99, 0.00, 0.00, 0.01, 0.00, 1.00, 0.92, 0.02, 1.00,\n",
       "       0.00, 0.37, 0.98, 0.12, 1.00, 0.00, 0.78, 1.00, 1.00, 0.98, 0.00,\n",
       "       0.00, 0.00, 1.00, 0.00, 0.78, 0.12, 0.00, 0.99, 1.00, 1.00, 0.00,\n",
       "       0.30, 1.00, 1.00, 0.00, 1.00, 1.00, 0.85, 1.00, 1.00, 0.00, 1.00,\n",
       "       1.00, 0.89, 0.83, 0.00, 0.98, 0.97, 0.00, 1.00, 1.00, 0.03, 0.99,\n",
       "       0.96, 1.00, 0.00, 1.00, 0.01, 0.01, 1.00, 1.00, 1.00, 0.00, 0.00,\n",
       "       0.02, 0.33, 0.00, 1.00, 0.09, 0.00, 0.97, 0.00, 0.75, 1.00, 1.00,\n",
       "       0.01, 0.01, 0.00, 1.00, 0.00, 0.99, 0.57, 0.54, 0.87, 0.83, 0.00,\n",
       "       1.00, 0.00, 0.00, 0.00, 1.00, 0.04, 0.00, 0.01, 1.00, 0.99, 0.52,\n",
       "       1.00, 1.00, 0.05, 0.00, 0.00, 0.00, 0.68, 1.00, 1.00, 1.00, 1.00,\n",
       "       1.00, 0.00, 1.00, 1.00, 0.04, 1.00, 0.02, 1.00, 0.99, 0.97, 0.94,\n",
       "       0.01, 0.00, 0.00])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.set_printoptions(formatter = {'float': lambda x: \"{0:0.2f}\".format(x)})\n",
    "print(\"predicted values\")\n",
    "print(\"\\n\")\n",
    "log_reg_result.predict()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "This section will deal on how can we interpret the Pseudo R squared in more meaningful way\n",
    "\n",
    "We see that there 0, 1 and some values in between. The values here are probabilities or odds log(pie)/log(1-pie). \n",
    "\n",
    "Ultimately, if the value is below 0.05 -> the probability of the admission is less than 50%\n",
    "\n",
    "Likewise, if the value is above 0.05 -> there is a high chance (more than 50%) that they will get admitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual values\n",
      "\n",
      "\n",
      "[0 1 1 0 0 1 1 1 1 0 1 1 1 0 0 1 0 0 1 1 1 1 0 0 1 1 1 1 1 1 0 1 0 1 1 1 0\n",
      " 1 0 0 0 1 1 0 1 0 1 0 0 0 0 1 0 0 1 0 0 1 0 1 0 1 1 1 1 0 0 0 1 0 1 1 0 1\n",
      " 1 1 0 1 1 1 0 1 1 0 1 1 0 1 1 1 0 0 1 1 0 1 1 0 1 1 1 0 1 0 0 1 1 1 0 0 0\n",
      " 0 0 1 0 0 1 0 1 1 1 0 0 0 1 0 1 0 1 1 1 0 1 0 0 0 1 0 0 0 1 1 1 1 1 0 0 0\n",
      " 0 1 1 1 1 1 1 0 1 1 0 1 0 1 1 1 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(\"actual values\")\n",
    "print(\"\\n\")\n",
    "print(np.array(y))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Comparing between \"predicted values\" and \"actual values\", we can already make assumptions that these two can be compared and assess their accuracy\n",
    "\n",
    "The easiest way to do so is by using pred_table method by statsmodels. This table is an exact replica of confusion matrix. The method will calculate itself whereby if the predicted value is less than 0.5, it is rounded down to 0, and if it is greater than or equal to 0.5, it is rounded up to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[69.00, 5.00],\n",
       "       [4.00, 90.00]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg_result.pred_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 0</th>\n",
       "      <th>Predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>69.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 0  Predicted 1\n",
       "Actual 0         69.0          5.0\n",
       "Actual 1          4.0         90.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_df = pd.DataFrame(log_reg_result.pred_table())\n",
    "cm_df.columns = ['Predicted 0', 'Predicted 1']\n",
    "\n",
    "cm_df = cm_df.rename(index = {0: \"Actual 0\", 1: \"Actual 1\"})\n",
    "\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94.64285714285714"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculating the accuracy of the model\n",
    "\n",
    "obs = ((69+90)/(69+90+9)) * 100\n",
    "obs"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Observing this confusion matrix, we see that there are:\n",
    "\n",
    "69 observations that actual is 0 and the model predicts 0\n",
    "90 observationst that actual is 1 and the model predicts 1\n",
    "however, 9 observations have been predicted wrongly\n",
    "which leaves us that ((69+90)/(69+90+9)) that the model is 94.6% accurate!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expanding the model by using all predictors, and calculate the accuracy of the model - Multivariate Logistic Regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can be omitting many causal factors in our simple logistic model, so we instead switch to a multivariate logistic regression model. Add the ‘interest_rate’, ‘march’, ‘credit’ and ‘previous’ estimators to our model and run the regression again. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_all = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1.]\n",
      "[1. 0.]\n",
      "[0. 2. 1. 3. 4. 5.]\n",
      "[0. 1.]\n",
      "[0 1]\n",
      "\n",
      "\n",
      "[0. 1.]\n",
      "[1. 0.]\n",
      "[0. 1.]\n",
      "[0. 1.]\n",
      "[0 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "interest_rate    0\n",
       "credit           0\n",
       "march            0\n",
       "may              0\n",
       "previous         0\n",
       "duration         0\n",
       "y                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove or drop the Unnamed: 0 column\n",
    "\n",
    "new_df_all = new_df_all.drop(['Unnamed: 0'], axis = 1)\n",
    "\n",
    "# Assign boolean values in the y column\n",
    "\n",
    "new_df_all['y'] = new_df_all['y'].map({'yes': 1, 'no':0})\n",
    "\n",
    "# Checking the boolean values in the relevant columns\n",
    "\n",
    "boolean = ['credit', 'march', 'may', 'previous', 'y']\n",
    "\n",
    "for i in boolean:\n",
    "    print(new_df_all[i].unique())\n",
    "                             \n",
    "# Fixing assignments of values in may when > 1 as 1\n",
    "\n",
    "new_df_all.loc[new_df_all['may'] > 1, ['may']] = 1\n",
    "\n",
    "# Checking (again)the boolean values in the relevant columns\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "boolean = ['credit', 'march', 'may', 'previous', 'y']\n",
    "\n",
    "for i in boolean:\n",
    "    print(new_df_all[i].unique())\n",
    "    \n",
    "# Checking for null/missing values\n",
    "\n",
    "new_df_all.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>interest_rate</th>\n",
       "      <th>credit</th>\n",
       "      <th>march</th>\n",
       "      <th>may</th>\n",
       "      <th>previous</th>\n",
       "      <th>duration</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>518.000000</td>\n",
       "      <td>518.000000</td>\n",
       "      <td>518.000000</td>\n",
       "      <td>518.000000</td>\n",
       "      <td>518.000000</td>\n",
       "      <td>518.000000</td>\n",
       "      <td>518.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.835776</td>\n",
       "      <td>0.034749</td>\n",
       "      <td>0.266409</td>\n",
       "      <td>0.247104</td>\n",
       "      <td>0.127413</td>\n",
       "      <td>382.177606</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.876903</td>\n",
       "      <td>0.183321</td>\n",
       "      <td>0.442508</td>\n",
       "      <td>0.431745</td>\n",
       "      <td>0.333758</td>\n",
       "      <td>344.295990</td>\n",
       "      <td>0.500483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.635000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.042750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.466000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>266.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.956500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>482.750000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.970000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2653.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       interest_rate      credit       march         may    previous  \\\n",
       "count     518.000000  518.000000  518.000000  518.000000  518.000000   \n",
       "mean        2.835776    0.034749    0.266409    0.247104    0.127413   \n",
       "std         1.876903    0.183321    0.442508    0.431745    0.333758   \n",
       "min         0.635000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%         1.042750    0.000000    0.000000    0.000000    0.000000   \n",
       "50%         1.466000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%         4.956500    0.000000    1.000000    0.000000    0.000000   \n",
       "max         4.970000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "          duration           y  \n",
       "count   518.000000  518.000000  \n",
       "mean    382.177606    0.500000  \n",
       "std     344.295990    0.500483  \n",
       "min       9.000000    0.000000  \n",
       "25%     155.000000    0.000000  \n",
       "50%     266.500000    0.500000  \n",
       "75%     482.750000    1.000000  \n",
       "max    2653.000000    1.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df_all.describe(include = 'all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Declare the dependent and independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>interest_rate</th>\n",
       "      <th>credit</th>\n",
       "      <th>march</th>\n",
       "      <th>may</th>\n",
       "      <th>previous</th>\n",
       "      <th>duration</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.334</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.767</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>274.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.858</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.120</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>686.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.856</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>1.334</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>0.861</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>806.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>0.879</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>290.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>0.877</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>473.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>4.965</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>518 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     interest_rate  credit  march  may  previous  duration  y\n",
       "0            1.334     0.0    1.0  0.0       0.0     117.0  0\n",
       "1            0.767     0.0    0.0  1.0       1.0     274.0  1\n",
       "2            4.858     0.0    1.0  0.0       0.0     167.0  0\n",
       "3            4.120     0.0    0.0  0.0       0.0     686.0  1\n",
       "4            4.856     0.0    1.0  0.0       0.0     157.0  0\n",
       "..             ...     ...    ...  ...       ...       ... ..\n",
       "513          1.334     0.0    1.0  0.0       0.0     204.0  0\n",
       "514          0.861     0.0    0.0  1.0       1.0     806.0  1\n",
       "515          0.879     0.0    0.0  0.0       0.0     290.0  0\n",
       "516          0.877     0.0    0.0  1.0       1.0     473.0  1\n",
       "517          4.965     0.0    0.0  0.0       0.0     142.0  0\n",
       "\n",
       "[518 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First of all, we need to understand of how we can observe continuous variables against the y\n",
    "# Among all of the predictors, duration is the only variable that is in that nature\n",
    "# We will do this so that we can illustrate how this variable affects the y\n",
    "\n",
    "x1 = new_df_all['duration']\n",
    "y = new_df_all['y']\n",
    "\n",
    "# Next, we do interest rate\n",
    "\n",
    "x2 = new_df_all['interest_rate']\n",
    "\n",
    "# We will create another dataframe for all interested variables too\n",
    "\n",
    "x3 = new_df_all[['interest_rate','credit','march','may','previous','duration']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.546118\n",
      "         Iterations 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>              <td>Logit</td>      <td>Pseudo R-squared:</td>    <td>0.212</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>         <td>y</td>              <td>AIC:</td>         <td>569.7778</td> \n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2023-06-25 12:59</td>       <td>BIC:</td>         <td>578.2778</td> \n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>         <td>518</td>        <td>Log-Likelihood:</td>    <td>-282.89</td> \n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>              <td>1</td>            <td>LL-Null:</td>        <td>-359.05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>           <td>516</td>         <td>LLR p-value:</td>    <td>5.3865e-35</td>\n",
       "</tr>\n",
       "<tr>\n",
       "      <td>Converged:</td>           <td>1.0000</td>           <td>Scale:</td>         <td>1.0000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "    <td>No. Iterations:</td>        <td>7.0000</td>              <td></td>               <td></td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>      <th>Coef.</th>  <th>Std.Err.</th>    <th>z</th>     <th>P>|z|</th> <th>[0.025</th>  <th>0.975]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>    <td>-1.7001</td>  <td>0.1918</td>  <td>-8.8635</td> <td>0.0000</td> <td>-2.0761</td> <td>-1.3242</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>duration</th> <td>0.0051</td>   <td>0.0006</td>  <td>9.1594</td>  <td>0.0000</td> <td>0.0040</td>  <td>0.0062</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                         Results: Logit\n",
       "=================================================================\n",
       "Model:              Logit            Pseudo R-squared: 0.212     \n",
       "Dependent Variable: y                AIC:              569.7778  \n",
       "Date:               2023-06-25 12:59 BIC:              578.2778  \n",
       "No. Observations:   518              Log-Likelihood:   -282.89   \n",
       "Df Model:           1                LL-Null:          -359.05   \n",
       "Df Residuals:       516              LLR p-value:      5.3865e-35\n",
       "Converged:          1.0000           Scale:            1.0000    \n",
       "No. Iterations:     7.0000                                       \n",
       "------------------------------------------------------------------\n",
       "               Coef.   Std.Err.     z     P>|z|    [0.025   0.975]\n",
       "------------------------------------------------------------------\n",
       "const         -1.7001    0.1918  -8.8635  0.0000  -2.0761  -1.3242\n",
       "duration       0.0051    0.0006   9.1594  0.0000   0.0040   0.0062\n",
       "=================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Proceed first with doing logistic regression using duration as the only independent variables\n",
    "\n",
    "X1 =  sm.add_constant(x1)\n",
    "log_reg_dur = sm.Logit(y,X1)\n",
    "log_reg_res_dur = log_reg_dur.fit()\n",
    "\n",
    "log_reg_res_dur.summary2()\n",
    "\n",
    "# Note that, for a simple log regression with only using the variables, Log-likehood is still considerably bigger than the LL-null\n",
    "# in terms of magnitude\n",
    "# Let's see if we can do this better with we incorporate all variables (more on this later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Predicting the probabilities for Subcrscription model based on duration\n",
    "plt.scatter(x1,y, color ='blue')\n",
    "plt.xlabel('duration', fontsize = 15)\n",
    "plt.ylabel('subscription', fontsize = 15)\n",
    "\n",
    "# Predict probabilities for each value of duration\n",
    "x_range = x1\n",
    "y_pred = log_reg_res_dur.predict(sm.add_constant(x1))\n",
    "\n",
    "# Add a line plot of the predicted probabilities to the scatter plot\n",
    "plt.scatter(x_range, y_pred, color='red')\n",
    "plt.show()\n",
    "\n",
    "# As we can see, duration alone cannot be the only determining factor in deciding the subscription# Although we can that the pattern such as that above 1,000 days since last contacted, there is chance that customers might subscribe\n",
    "# But we could not said the same those with shorter period of time < 1,000 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.568641\n",
      "         Iterations 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>              <td>Logit</td>      <td>Pseudo R-squared:</td>    <td>0.180</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>         <td>y</td>              <td>AIC:</td>         <td>593.1121</td> \n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2023-06-25 12:59</td>       <td>BIC:</td>         <td>601.6120</td> \n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>         <td>518</td>        <td>Log-Likelihood:</td>    <td>-294.56</td> \n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>              <td>1</td>            <td>LL-Null:</td>        <td>-359.05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>           <td>516</td>         <td>LLR p-value:</td>    <td>6.8216e-30</td>\n",
       "</tr>\n",
       "<tr>\n",
       "      <td>Converged:</td>           <td>1.0000</td>           <td>Scale:</td>         <td>1.0000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "    <td>No. Iterations:</td>        <td>5.0000</td>              <td></td>               <td></td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>         <th>Coef.</th>  <th>Std.Err.</th>     <th>z</th>     <th>P>|z|</th> <th>[0.025</th>  <th>0.975]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>         <td>1.6146</td>   <td>0.1815</td>   <td>8.8963</td>  <td>0.0000</td> <td>1.2589</td>  <td>1.9704</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>interest_rate</th> <td>-0.5734</td>  <td>0.0544</td>  <td>-10.5313</td> <td>0.0000</td> <td>-0.6801</td> <td>-0.4667</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                         Results: Logit\n",
       "=================================================================\n",
       "Model:              Logit            Pseudo R-squared: 0.180     \n",
       "Dependent Variable: y                AIC:              593.1121  \n",
       "Date:               2023-06-25 12:59 BIC:              601.6120  \n",
       "No. Observations:   518              Log-Likelihood:   -294.56   \n",
       "Df Model:           1                LL-Null:          -359.05   \n",
       "Df Residuals:       516              LLR p-value:      6.8216e-30\n",
       "Converged:          1.0000           Scale:            1.0000    \n",
       "No. Iterations:     5.0000                                       \n",
       "-----------------------------------------------------------------\n",
       "                  Coef.  Std.Err.    z     P>|z|   [0.025  0.975]\n",
       "-----------------------------------------------------------------\n",
       "const             1.6146   0.1815   8.8963 0.0000  1.2589  1.9704\n",
       "interest_rate    -0.5734   0.0544 -10.5313 0.0000 -0.6801 -0.4667\n",
       "=================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Next, we continue with interest rate as the only independent variables\n",
    "\n",
    "X2 =  sm.add_constant(x2)\n",
    "log_reg_rate = sm.Logit(y,X2)\n",
    "log_reg_res_rate = log_reg_rate.fit()\n",
    "\n",
    "log_reg_res_rate.summary2()\n",
    "\n",
    "# Very similar to the previous results..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Predicting the probabilities for Subcrscription model based on interest rate\n",
    "plt.scatter(x2,y, color ='blue')\n",
    "plt.xlabel('interest_rate', fontsize = 15)\n",
    "plt.ylabel('subscription', fontsize = 15)\n",
    "\n",
    "# Predict probabilities for each value of interest_rate\n",
    "x_range = x2\n",
    "y_pred = log_reg_res_rate.predict(sm.add_constant(x2))\n",
    "\n",
    "# Add a line plot of the predicted probabilities to the scatter plot\n",
    "plt.scatter(x_range, y_pred, color='red')\n",
    "plt.show()\n",
    "\n",
    "# The plot shows that there is high concentration of subscription whereby if the interest_rate is low# Prediction is way off for both low and high regimes of interest_rate, espeically so in the low regime where subscription is the subset of 1 and 0\n",
    "# where interest_rate is predicted to influence the customers to subscrine, whihc isn't the case# Same goes to higher interest regime, where prediction does not match to those subscribe anyway\n",
    "# Again, irregardless of the interest rates, customers choose to subscribe anyway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197\n",
      "76\n",
      "0.7216117216117216\n",
      "62\n",
      "183\n",
      "0.2530612244897959\n"
     ]
    }
   ],
   "source": [
    "# Probability of subscription when interest rate is below 3\n",
    "\n",
    "below_3_yes = new_df_all.loc[(new_df_all['y'] == 1) & (new_df_all['interest_rate'] < 2), ['interest_rate']]\n",
    "below_3_no = new_df_all.loc[(new_df_all['y'] == 0) & (new_df_all['interest_rate'] < 2), ['interest_rate']]\n",
    "\n",
    "print(below_3_yes['interest_rate'].shape[0])\n",
    "print(below_3_no['interest_rate'].shape[0])\n",
    "\n",
    "print((below_3_yes.shape[0])/(below_3_yes.shape[0] + below_3_no.shape[0]))\n",
    "\n",
    "# Probability of subscription when interest rate is above 3\n",
    "\n",
    "above_3_yes = new_df_all.loc[(new_df_all['y'] == 1) & (new_df_all['interest_rate'] > 2), ['interest_rate']]\n",
    "above_3_no = new_df_all.loc[(new_df_all['y'] == 0) & (new_df_all['interest_rate'] > 2), ['interest_rate']]\n",
    "\n",
    "print(above_3_yes['interest_rate'].shape[0])\n",
    "print(above_3_no['interest_rate'].shape[0])\n",
    "\n",
    "print((above_3_yes.shape[0])/(above_3_yes.shape[0] + above_3_no.shape[0]))\n",
    "\n",
    "\n",
    "#above_3 = new_df_all.loc[(new_df_all['y'] == 1) & (new_df_all['interest_rate'] < 2), ['interest_rate']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.335824\n",
      "         Iterations 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>              <td>Logit</td>      <td>Pseudo R-squared:</td>    <td>0.516</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>         <td>y</td>              <td>AIC:</td>         <td>361.9138</td> \n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2023-06-25 13:00</td>       <td>BIC:</td>         <td>391.6636</td> \n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>         <td>518</td>        <td>Log-Likelihood:</td>    <td>-173.96</td> \n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>              <td>6</td>            <td>LL-Null:</td>        <td>-359.05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>           <td>511</td>         <td>LLR p-value:</td>    <td>7.1356e-77</td>\n",
       "</tr>\n",
       "<tr>\n",
       "      <td>Converged:</td>           <td>1.0000</td>           <td>Scale:</td>         <td>1.0000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "    <td>No. Iterations:</td>        <td>7.0000</td>              <td></td>               <td></td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>         <th>Coef.</th>  <th>Std.Err.</th>    <th>z</th>     <th>P>|z|</th> <th>[0.025</th>  <th>0.975]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>         <td>0.1317</td>   <td>0.3534</td>  <td>0.3726</td>  <td>0.7094</td> <td>-0.5610</td> <td>0.8244</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>interest_rate</th> <td>-0.8267</td>  <td>0.0946</td>  <td>-8.7360</td> <td>0.0000</td> <td>-1.0122</td> <td>-0.6413</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>credit</th>        <td>2.3249</td>   <td>1.0891</td>  <td>2.1347</td>  <td>0.0328</td> <td>0.1903</td>  <td>4.4594</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>march</th>         <td>-1.8651</td>  <td>0.3324</td>  <td>-5.6107</td> <td>0.0000</td> <td>-2.5166</td> <td>-1.2135</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>may</th>           <td>-0.3628</td>  <td>0.3893</td>  <td>-0.9319</td> <td>0.3514</td> <td>-1.1259</td> <td>0.4002</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>previous</th>      <td>1.7903</td>   <td>0.5703</td>  <td>3.1391</td>  <td>0.0017</td> <td>0.6725</td>  <td>2.9080</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>duration</th>      <td>0.0069</td>   <td>0.0007</td>  <td>9.3700</td>  <td>0.0000</td> <td>0.0055</td>  <td>0.0084</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                         Results: Logit\n",
       "=================================================================\n",
       "Model:              Logit            Pseudo R-squared: 0.516     \n",
       "Dependent Variable: y                AIC:              361.9138  \n",
       "Date:               2023-06-25 13:00 BIC:              391.6636  \n",
       "No. Observations:   518              Log-Likelihood:   -173.96   \n",
       "Df Model:           6                LL-Null:          -359.05   \n",
       "Df Residuals:       511              LLR p-value:      7.1356e-77\n",
       "Converged:          1.0000           Scale:            1.0000    \n",
       "No. Iterations:     7.0000                                       \n",
       "-----------------------------------------------------------------\n",
       "                   Coef.  Std.Err.    z    P>|z|   [0.025  0.975]\n",
       "-----------------------------------------------------------------\n",
       "const              0.1317   0.3534  0.3726 0.7094 -0.5610  0.8244\n",
       "interest_rate     -0.8267   0.0946 -8.7360 0.0000 -1.0122 -0.6413\n",
       "credit             2.3249   1.0891  2.1347 0.0328  0.1903  4.4594\n",
       "march             -1.8651   0.3324 -5.6107 0.0000 -2.5166 -1.2135\n",
       "may               -0.3628   0.3893 -0.9319 0.3514 -1.1259  0.4002\n",
       "previous           1.7903   0.5703  3.1391 0.0017  0.6725  2.9080\n",
       "duration           0.0069   0.0007  9.3700 0.0000  0.0055  0.0084\n",
       "=================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X3 = sm.add_constant(x3)\n",
    "log_reg_all = sm.Logit(y,X3)\n",
    "log_reg_all_res = log_reg_all.fit()\n",
    "\n",
    "log_reg_all_res.summary2()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Fitting the model results in 7 iterations\n",
    "\n",
    "All observations have been estimated\n",
    "\n",
    "Pseudo R-squared: 0.56, which pointing towards that the model has the best fitted model compared the last two\n",
    "\n",
    "The Log-Likelihood and LL-Null are both not converging but in terms of its relative magnitude, this model is much higher than the last two\n",
    "\n",
    "This is furhter supported by LLR p-value, which is significantly smaller than the last two model\n",
    "\n",
    "This means that the model has variables that explains its variability that is reflected in both Presudo R-squared and the log likelihood\n",
    "\n",
    "On the coefficient side, the weight of the predictors from the previous two models are -0.5734 for interest_rate and 0.0051 for duration.\n",
    "Now that we have accounted all other variables, both of these predictors are now showing higher weights in this model.\n",
    "This could mean that the inclusion of other variables has helped to better capture the relationship between the outcome and the variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting and calculating the accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(data,actual_values,model):\n",
    "        \n",
    "        # Confusion matrix \n",
    "        \n",
    "        # Parameters\n",
    "        # ----------\n",
    "        # data: data frame or array\n",
    "            # data is a data frame formatted in the same way as your input data (without the actual values)\n",
    "            # e.g. const, var1, var2, etc. Order is very important!\n",
    "        # actual_values: data frame or array\n",
    "            # These are the actual values from the test_data\n",
    "            # In the case of a logistic regression, it should be a single column with 0s and 1s\n",
    "            \n",
    "        # model: a LogitResults object\n",
    "            # this is the variable where you have the fitted model \n",
    "            # e.g. results_log in this course\n",
    "        # ----------\n",
    "        \n",
    "        #Predict the values using the Logit model where the predict() will assign any values to either 1s or 0s where the threshold is 0.05\n",
    "        pred_values = model.predict(data)\n",
    "        # Specify the bins \n",
    "        bins=np.array([0,0.5,1])\n",
    "        # Create a histogram, where if values are between 0 and 0.5 tell will be considered 0\n",
    "        # if they are between 0.5 and 1, they will be considered 1\n",
    "        cm = np.histogram2d(actual_values, pred_values, bins=bins)[0]\n",
    "        # Calculate the accuracy\n",
    "        accuracy = (cm[0,0]+cm[1,1])/cm.sum()\n",
    "        # Return the confusion matrix and \n",
    "        cm = pd.DataFrame(cm)\n",
    "        cm.columns = ['Predicted 0', 'Predicted 1']\n",
    "        cm = cm.rename(index = {0: 'Actual 0', 1: 'Actual 1'})\n",
    "        cm\n",
    "        return cm, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(          Predicted 0  Predicted 1\n",
       " Actual 0        204.0         55.0\n",
       " Actual 1        104.0        155.0,\n",
       " 0.693050193050193)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First (duration) model\n",
    "\n",
    "confusion_matrix(X1,y,log_reg_res_dur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(          Predicted 0  Predicted 1\n",
       " Actual 0        183.0         76.0\n",
       " Actual 1         62.0        197.0,\n",
       " 0.7335907335907336)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Second (interest_rate) model\n",
    "\n",
    "confusion_matrix(X2,y,log_reg_res_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(          Predicted 0  Predicted 1\n",
       " Actual 0        220.0         39.0\n",
       " Actual 1         27.0        232.0,\n",
       " 0.8725868725868726)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multivariate model\n",
    "\n",
    "confusion_matrix(X3,y,log_reg_all_res)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "As we can see, comparing all these 3 models, multivariate model shows a much more higher accuracy between the three!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eliminating the possibilities of Overtraining the model (splitting datasets)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "In this lesson, we want to overcome the possibilities of overfitting by splitting the data to test and train\n",
    "\n",
    "First, let's see how the model is trained upon using the train datasets before we use the test data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_all_2 = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1.]\n",
      "[1. 0.]\n",
      "[0. 2. 1. 3. 4. 5.]\n",
      "[0. 1.]\n",
      "[0 1]\n",
      "\n",
      "\n",
      "[0. 1.]\n",
      "[1. 0.]\n",
      "[0. 2. 1. 3. 4. 5.]\n",
      "[0. 1.]\n",
      "[0 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "interest_rate    0\n",
       "credit           0\n",
       "march            0\n",
       "may              0\n",
       "previous         0\n",
       "duration         0\n",
       "y                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove or drop the Unnamed: 0 column\n",
    "\n",
    "new_df_all_2 = new_df_all_2.drop(['Unnamed: 0'], axis = 1)\n",
    "\n",
    "# Assign boolean values in the y column\n",
    "\n",
    "new_df_all_2['y'] = new_df_all_2['y'].map({'yes': 1, 'no':0})\n",
    "\n",
    "# Checking the boolean values in the relevant columns\n",
    "\n",
    "boolean = ['credit', 'march', 'may', 'previous', 'y']\n",
    "\n",
    "for i in boolean:\n",
    "    print(new_df_all_2[i].unique())\n",
    "                             \n",
    "# Fixing assignments of values in may when > 1 as 1\n",
    "\n",
    "new_df_all_2.loc[new_df_all['may'] > 1, ['may']] = 1\n",
    "\n",
    "# Checking (again)the boolean values in the relevant columns\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "boolean = ['credit', 'march', 'may', 'previous', 'y']\n",
    "\n",
    "for i in boolean:\n",
    "    print(new_df_all_2[i].unique())\n",
    "    \n",
    "# Checking for null/missing values\n",
    "\n",
    "new_df_all_2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>interest_rate</th>\n",
       "      <th>credit</th>\n",
       "      <th>march</th>\n",
       "      <th>may</th>\n",
       "      <th>previous</th>\n",
       "      <th>duration</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>518.000000</td>\n",
       "      <td>518.000000</td>\n",
       "      <td>518.000000</td>\n",
       "      <td>518.000000</td>\n",
       "      <td>518.000000</td>\n",
       "      <td>518.000000</td>\n",
       "      <td>518.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.835776</td>\n",
       "      <td>0.034749</td>\n",
       "      <td>0.266409</td>\n",
       "      <td>0.388031</td>\n",
       "      <td>0.127413</td>\n",
       "      <td>382.177606</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.876903</td>\n",
       "      <td>0.183321</td>\n",
       "      <td>0.442508</td>\n",
       "      <td>0.814527</td>\n",
       "      <td>0.333758</td>\n",
       "      <td>344.295990</td>\n",
       "      <td>0.500483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.635000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.042750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.466000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>266.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.956500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>482.750000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.970000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2653.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       interest_rate      credit       march         may    previous  \\\n",
       "count     518.000000  518.000000  518.000000  518.000000  518.000000   \n",
       "mean        2.835776    0.034749    0.266409    0.388031    0.127413   \n",
       "std         1.876903    0.183321    0.442508    0.814527    0.333758   \n",
       "min         0.635000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%         1.042750    0.000000    0.000000    0.000000    0.000000   \n",
       "50%         1.466000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%         4.956500    0.000000    1.000000    0.000000    0.000000   \n",
       "max         4.970000    1.000000    1.000000    5.000000    1.000000   \n",
       "\n",
       "          duration           y  \n",
       "count   518.000000  518.000000  \n",
       "mean    382.177606    0.500000  \n",
       "std     344.295990    0.500483  \n",
       "min       9.000000    0.000000  \n",
       "25%     155.000000    0.000000  \n",
       "50%     266.500000    0.500000  \n",
       "75%     482.750000    1.000000  \n",
       "max    2653.000000    1.000000  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df_all_2.describe(include = 'all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare the dependent and independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As per usual, we will assign the variables just like for our miltivariate logistic regression\n",
    "\n",
    "y = new_df_all_2['y']\n",
    "\n",
    "x3 = new_df_all_2[['interest_rate','credit','march','may','previous','duration']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "518\n",
      "Size of the training dataset:  414\n",
      "Size of the testing dataset:  104\n",
      "Columns order of the training dataset:  Index(['interest_rate', 'credit', 'march', 'may', 'previous', 'duration'], dtype='object')\n",
      "Columns order of the testing dataset:  Index(['interest_rate', 'credit', 'march', 'may', 'previous', 'duration'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>const</th>\n",
       "      <th>interest_rate</th>\n",
       "      <th>credit</th>\n",
       "      <th>march</th>\n",
       "      <th>may</th>\n",
       "      <th>previous</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.281</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>829.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.855</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>135.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>767.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.677</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>211.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.965</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>119.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>286.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.856</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>374.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.964</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>111.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.811</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1447.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>104 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     const  interest_rate  credit  march  may  previous  duration\n",
       "453    1.0          1.281     0.0    1.0  1.0       0.0     829.0\n",
       "436    1.0          4.855     0.0    1.0  0.0       0.0     135.0\n",
       "62     1.0          1.000     0.0    0.0  0.0       0.0     767.0\n",
       "195    1.0          4.959     0.0    0.0  0.0       0.0      11.0\n",
       "475    1.0          0.677     0.0    1.0  4.0       1.0     211.0\n",
       "..     ...            ...     ...    ...  ...       ...       ...\n",
       "116    1.0          4.965     0.0    0.0  0.0       0.0     119.0\n",
       "143    1.0          0.767     0.0    0.0  0.0       0.0     286.0\n",
       "402    1.0          4.856     0.0    1.0  0.0       0.0     374.0\n",
       "323    1.0          4.964     0.0    0.0  0.0       0.0     111.0\n",
       "38     1.0          1.811     1.0    0.0  0.0       0.0    1447.0\n",
       "\n",
       "[104 rows x 7 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data set\n",
    "# Split the variables with an 80-20 split and some random state\n",
    "# To have the same split, use random_state = 365\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x3, y, test_size = 0.2, random_state = 365)\n",
    "\n",
    "# Verifying the shape of the training set and testing set\n",
    "# Ideally, we want our training data to have the most data than our testing data\n",
    "\n",
    "print(x3.shape[0])\n",
    "print(\"Size of the training dataset: \", x_train.shape[0])\n",
    "print(\"Size of the testing dataset: \", x_test.shape[0])\n",
    "\n",
    "# We also need to ensure that the columns orders of the train and test are both the same\n",
    "\n",
    "print(\"Columns order of the training dataset: \", x_train.columns)\n",
    "print(\"Columns order of the testing dataset: \", x_test.columns)\n",
    "\n",
    "# To prepare for the testing of our data, we can add constant to our testing data to match with the training data\n",
    "\n",
    "X_test = sm.add_constant(x_test) \n",
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.337974\n",
      "         Iterations 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>              <td>Logit</td>      <td>Pseudo R-squared:</td>    <td>0.512</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>         <td>y</td>              <td>AIC:</td>         <td>293.8425</td> \n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2023-06-25 13:00</td>       <td>BIC:</td>         <td>322.0235</td> \n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>         <td>414</td>        <td>Log-Likelihood:</td>    <td>-139.92</td> \n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>              <td>6</td>            <td>LL-Null:</td>        <td>-286.94</td> \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>           <td>407</td>         <td>LLR p-value:</td>    <td>1.5440e-60</td>\n",
       "</tr>\n",
       "<tr>\n",
       "      <td>Converged:</td>           <td>1.0000</td>           <td>Scale:</td>         <td>1.0000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "    <td>No. Iterations:</td>        <td>7.0000</td>              <td></td>               <td></td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>         <th>Coef.</th>  <th>Std.Err.</th>    <th>z</th>     <th>P>|z|</th> <th>[0.025</th>  <th>0.975]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>         <td>-0.1417</td>  <td>0.3775</td>  <td>-0.3753</td> <td>0.7074</td> <td>-0.8816</td> <td>0.5982</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>interest_rate</th> <td>-0.7637</td>  <td>0.1024</td>  <td>-7.4563</td> <td>0.0000</td> <td>-0.9645</td> <td>-0.5630</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>credit</th>        <td>2.1890</td>   <td>1.1042</td>  <td>1.9824</td>  <td>0.0474</td> <td>0.0248</td>  <td>4.3532</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>march</th>         <td>-2.0190</td>  <td>0.3872</td>  <td>-5.2142</td> <td>0.0000</td> <td>-2.7779</td> <td>-1.2601</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>may</th>           <td>0.0695</td>   <td>0.2564</td>  <td>0.2712</td>  <td>0.7862</td> <td>-0.4330</td> <td>0.5720</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>previous</th>      <td>1.4378</td>   <td>0.6778</td>  <td>2.1214</td>  <td>0.0339</td> <td>0.1094</td>  <td>2.7663</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>duration</th>      <td>0.0070</td>   <td>0.0008</td>  <td>8.6542</td>  <td>0.0000</td> <td>0.0054</td>  <td>0.0086</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                         Results: Logit\n",
       "=================================================================\n",
       "Model:              Logit            Pseudo R-squared: 0.512     \n",
       "Dependent Variable: y                AIC:              293.8425  \n",
       "Date:               2023-06-25 13:00 BIC:              322.0235  \n",
       "No. Observations:   414              Log-Likelihood:   -139.92   \n",
       "Df Model:           6                LL-Null:          -286.94   \n",
       "Df Residuals:       407              LLR p-value:      1.5440e-60\n",
       "Converged:          1.0000           Scale:            1.0000    \n",
       "No. Iterations:     7.0000                                       \n",
       "-----------------------------------------------------------------\n",
       "                   Coef.  Std.Err.    z    P>|z|   [0.025  0.975]\n",
       "-----------------------------------------------------------------\n",
       "const             -0.1417   0.3775 -0.3753 0.7074 -0.8816  0.5982\n",
       "interest_rate     -0.7637   0.1024 -7.4563 0.0000 -0.9645 -0.5630\n",
       "credit             2.1890   1.1042  1.9824 0.0474  0.0248  4.3532\n",
       "march             -2.0190   0.3872 -5.2142 0.0000 -2.7779 -1.2601\n",
       "may                0.0695   0.2564  0.2712 0.7862 -0.4330  0.5720\n",
       "previous           1.4378   0.6778  2.1214 0.0339  0.1094  2.7663\n",
       "duration           0.0070   0.0008  8.6542 0.0000  0.0054  0.0086\n",
       "=================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using the training dataset as benchmark for the regresion\n",
    "\n",
    "X_train = sm.add_constant(x_train) # Remember that we add constant into the training dataset, so we shall do the same (see above on the splitting dataset)\n",
    "log_reg_actual = sm.Logit(y_train,X_train)\n",
    "log_reg_actual_res = log_reg_actual.fit()\n",
    "\n",
    "log_reg_actual_res.summary2()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Fitting the model results in 7 iterations\n",
    "\n",
    "All observations have been estimated\n",
    "\n",
    "Pseudo R-squared: 0.512,\n",
    "\n",
    "The Log-Likelihood and LL-Null are both not converging but in terms of its relative magnitude, there are quite high\n",
    "\n",
    "This is furhter supported by LLR p-value\n",
    "\n",
    "This means that the model has variables that explains its variability that is reflected in both Presudo R-squared and the log likelihood\n",
    "\n",
    "On the coefficient side, the variables helped to better capture the relationship between the outcome and the variables. Let's ignore the details on the feature selection (particularly the p values) where May seems to be insignificant effect\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Predicting and calculating the accuracy of the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(data,actual_values,model):\n",
    "        \n",
    "        # Confusion matrix \n",
    "        \n",
    "        # Parameters\n",
    "        # ----------\n",
    "        # data: data frame or array\n",
    "            # data is a data frame formatted in the same way as your input data (without the actual values)\n",
    "            # e.g. const, var1, var2, etc. Order is very important!\n",
    "        # actual_values: data frame or array\n",
    "            # These are the actual values from the test_data\n",
    "            # In the case of a logistic regression, it should be a single column with 0s and 1s\n",
    "            \n",
    "        # model: a LogitResults object\n",
    "            # this is the variable where you have the fitted model \n",
    "            # e.g. results_log in this course\n",
    "        # ----------\n",
    "        \n",
    "        #Predict the values using the Logit model where the predict() will assign any values to either 1s or 0s where the threshold is 0.05\n",
    "        pred_values = model.predict(data)\n",
    "        # Specify the bins \n",
    "        bins=np.array([0,0.5,1])\n",
    "        # Create a histogram, where if values are between 0 and 0.5 tell will be considered 0\n",
    "        # if they are between 0.5 and 1, they will be considered 1\n",
    "        cm = np.histogram2d(actual_values, pred_values, bins=bins)[0]\n",
    "        # Calculate the accuracy\n",
    "        accuracy = (cm[0,0]+cm[1,1])/cm.sum()\n",
    "        # Calculate the misclassifcation\n",
    "        misclassification_rate = (cm[0,1]+cm[1,0])/cm.sum()\n",
    "        # Return the confusion matrix and \n",
    "        cm = pd.DataFrame(cm)\n",
    "        cm.columns = ['Predicted 0', 'Predicted 1']\n",
    "        cm = cm.rename(index = {0: 'Actual 0', 1: 'Actual 1'})\n",
    "        cm\n",
    "        return cm, accuracy, misclassification_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(          Predicted 0  Predicted 1\n",
       " Actual 0        174.0         31.0\n",
       " Actual 1         24.0        185.0,\n",
       " 0.8671497584541062,\n",
       " 0.13285024154589373)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_training = confusion_matrix(X_train,y_train,log_reg_actual_res)\n",
    "cm_training"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Based on the results above, the accuracy of the model is 86.71% and the misclassification_rate is 13.28%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(          Predicted 0  Predicted 1\n",
       " Actual 0         48.0          6.0\n",
       " Actual 1          7.0         43.0,\n",
       " 0.875,\n",
       " 0.125)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_testing = confusion_matrix(X_test, y_test, log_reg_actual_res)\n",
    "cm_testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the test acccuracy we see a number which is a tiny but lower: 86.71%, compared to 87.5% for train accuracy. \n",
    "\n",
    "In general, we always expect the test accuracy to be lower than the train one. If the test accuracy is higher, this is just due to luck.\n",
    "\n",
    "Note that when you run the regression, you may get different numbers than us!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
